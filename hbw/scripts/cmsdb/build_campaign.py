"""
This script is used to combine the dataset .txt files generated by the `parse_datasets.py` script.
The script can be run with the following command:
```
python3 combine_datasets.py -cpn <campaign>
```

Note that this script does not ensure that all datasets are unique and named correctly.
It is therefore essentially to manually check the resulting outputs and fix any issues before using
the files to build the campaign.
There are some details that always need to be checked manually:
- when adding datasets with additional keys in the DatasetInfo (e.g. hdamp_up), some manual adjustments are needed

It might be useful to run this script once directly after running the `parse_datasets.py` script and then
manually check the output files. After that, the outputs from the `parse_datasets.py` script can be filtered
to only include the datasets that are actually desired.
Additionally, the `my_get_das_info.py` script can be altered to follow certain naming conventions if needed.
"""


import os
import argparse
import subprocess

# Define the mapping of campaign names to sub-folder names
campaign_mapping = {
    "Run3Summer22NanoAODv12-130X": "run3_2022_preEE_nano_v12",
    "Run3Summer22EENanoAODv12-130X": "run3_2022_postEE_nano_v12",
    "Run3Summer23NanoAODv12-130X": "run3_2023_preBPix_nano_v12",
    "Run3Summer23BPixNanoAODv12-130X": "run3_2023_postBPix_nano_v12",
    "Run3Summer22NanoAODv13-133X": "run3_2022_preEE_nano_v13",
    "Run3Summer22EENanoAODv13-133X": "run3_2022_postEE_nano_v13",
    "Run3Summer23NanoAODv13-133X": "run3_2023_preBPix_nano_v13",
    "Run3Summer23BPixNanoAODv13-133X": "run3_2023_postBPix_nano_v13",
    # Add more mappings as needed
}

# Define the new output file mappings for combined keys
combined_output_mapping = {
    "data.py": ["data.txt"],
    "top.py": ["tt.txt", "st.txt", "ttv.txt"],
    "higgs.py": ["higgs.txt"],
    "hh2bbvv.py": ["hh2bbvv.txt"],
    "ewk.py": ["dy.txt", "w_lep.txt", "vv.txt"],
    "qcd.py": ["qcd.txt"],
}

dataset_header_map = {
    "data.py": "Data datasets",
    "top.py": "top quark datasets",
    "higgs.py": "Higgs boson datasets",
    "hh2bbvv.py": "HH -> bbVV datasets",
    "ewk.py": "Electroweak datasets",
    "qcd.py": "QCD datasets",
}


# Parse command-line arguments
parser = argparse.ArgumentParser(description="Combine dataset .txt files for a given campaign")
parser.add_argument("-cpn", "--campaign", required=True, help="Campaign name")
args = parser.parse_args()

das_campaign = args.campaign
if das_campaign not in campaign_mapping:
    raise ValueError(f"Unknown campaign: {das_campaign}; options: {', '.join(campaign_mapping.keys())}")
cmsdb_campaign = campaign_mapping[das_campaign]
campaign_parts = cmsdb_campaign.split("_")
campaign_info = {
    "tier": "NanoAOD",
    "run": campaign_parts[0].replace("run", ""),
    "year": campaign_parts[1],
    "version": campaign_parts[-1].replace("v", ""),
    "postfix": "TODO",
    "bx": 25,
}
campaign_info["ecm"] = 13.6 if int(campaign_info["run"]) == 2 else 13.0
campaign_info["id"] = f"{campaign_info['run']}{campaign_info['year']}{campaign_info['version']}{'01' if 'post' in cmsdb_campaign else '02'}"  # noqa: E501

output_dir = f"datasets/{das_campaign}"
final_output_dir = f"datasets/{das_campaign}/{cmsdb_campaign}"

header = lambda dataset: f"""
# coding: utf-8

\"\"\""
{dataset_header_map[dataset]} for the {cmsdb_campaign} campaign.
\"\"\"

from order import DatasetInfo

import cmsdb.processes as procs
from cmsdb.campaigns.{cmsdb_campaign} import campaign_{cmsdb_campaign} as cpn

"""

# Create the final output directory if it doesn't exist
os.makedirs(final_output_dir, exist_ok=True)

# Generate and run the combined commands
for combined_file, input_files in combined_output_mapping.items():

    input_paths = " ".join([
        os.path.join(output_dir, input_file)
        for input_file in input_files
        if os.path.exists(os.path.join(output_dir, input_file))
    ])
    if not input_paths:
        continue

    final_output_path = os.path.join(final_output_dir, combined_file)
    print(f"Combining datasets into {final_output_path}")
    subprocess.run(f"echo '{header(combined_file)}' > {final_output_path}", shell=True)
    command = f"python3 my_get_das_info.py -cpn smart -d {input_paths} >> {final_output_path}"
    print(f"Running command: {command}")
    subprocess.run(command, shell=True)

print("Writing __init__.py file")
init_str = f"""
# coding: utf-8

\"\"\"
Common, analysis independent definition of the {cmsdb_campaign} campaign
with datasets at NanoAOD tier in version {cmsdb_campaign.split("v")[-1]}.

See https://python-order.readthedocs.io/en/latest/quickstart.html#analysis-campaign-and-config.

Dataset ids are identical to those in DAS (https://cmsweb.cern.ch/das).
\"\"\"

from order import Campaign

#
# campaign
#

campaign_{cmsdb_campaign} = Campaign(
    name="{cmsdb_campaign}",
    id={campaign_info["id"]},
    ecm={campaign_info["ecm"]},
    bx={campaign_info["bx"]},
    aux={{
        "tier": "{campaign_info["tier"]}",
        "run": {campaign_info["run"]},
        "year": {campaign_info["year"]},
        "version": {campaign_info["version"]},
        "postfix": "{campaign_info["postfix"]}",
    }},
    tags={{"TODO"}},
)

# trailing imports to load datasets
import cmsdb.campaigns.{cmsdb_campaign}.data  # noqa
import cmsdb.campaigns.{cmsdb_campaign}.top  # noqa
import cmsdb.campaigns.{cmsdb_campaign}.ewk  # noqa
import cmsdb.campaigns.{cmsdb_campaign}.qcd  # noqa
import cmsdb.campaigns.{cmsdb_campaign}.higgs  # noqa
import cmsdb.campaigns.{cmsdb_campaign}.hh2bbvv  # noqa
"""

init_path = os.path.join(final_output_dir, "__init__.py")
subprocess.run(f"echo '{init_str}' > {init_path}", shell=True)

print(f"Finished combining datasets for {das_campaign} campaign")
